"""
çŸ¥è¯†åº“æ„å»ºè„šæœ¬

ç”¨äºä»æ–‡æ¡£æ„å»ºå‘é‡æ•°æ®åº“ï¼Œæ”¯æŒå¢é‡æ›´æ–°ã€‚
"""

import os
from pathlib import Path
from loguru import logger
from knowledge.document_loader import DocumentLoader
from knowledge.text_processor import TextProcessor
from knowledge.vectorizer import Vectorizer
from core.vector_store import ChromaVectorStore
from config import CHROMA_DB_PATH, CHUNK_SIZE, CHUNK_OVERLAP

class KnowledgeBaseBuilder:
    """çŸ¥è¯†åº“æ„å»ºå™¨"""
    
    def __init__(self):
        self.document_loader = DocumentLoader()
        self.text_processor = TextProcessor(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
        self.vectorizer = Vectorizer()
        self.vector_store = ChromaVectorStore()
        
    def build_knowledge_base(self, force_rebuild: bool = False):
        """
        æ„å»ºçŸ¥è¯†åº“
        
        Args:
            force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºï¼ˆåˆ é™¤ç°æœ‰æ•°æ®åº“ï¼‰
        """
        logger.info("å¼€å§‹æ„å»ºçŸ¥è¯†åº“...")
        
        # 1. æ£€æŸ¥æ–‡æ¡£
        doc_info = self.document_loader.get_document_info()
        logger.info(f"æ–‡æ¡£ç»Ÿè®¡: {doc_info}")
        
        if doc_info['supported_files'] == 0:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶")
            return False
            
        # 2. åŠ è½½æ–‡æ¡£
        documents = self.document_loader.load_all_documents()
        logger.info(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        
        # 3. æ–‡æœ¬å¤„ç†
        processed_chunks = self.text_processor.process_documents(documents)
        logger.info(f"ç”Ÿæˆäº† {len(processed_chunks)} ä¸ªæ–‡æœ¬å—")
        
        # 4. å‘é‡åŒ–æ–‡æ¡£
        encoded_docs = self.vectorizer.encode_documents(processed_chunks)
        logger.info(f"å‘é‡åŒ–å®Œæˆ: {len(encoded_docs)} ä¸ªæ–‡æ¡£")
        
        # 5. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        if force_rebuild:
            # åˆ é™¤ç°æœ‰é›†åˆ
            self.vector_store.delete_collection()
            # é‡æ–°åˆå§‹åŒ–
            self.vector_store = ChromaVectorStore()
            
        success = self.vector_store.add_documents(encoded_docs)
        
        if success:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            info = self.vector_store.get_collection_info()
            logger.info(f"çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯: {info}")
        else:
            logger.error("çŸ¥è¯†åº“æ„å»ºå¤±è´¥")
            
        return success

def main():
    """ä¸»å‡½æ•°"""
    builder = KnowledgeBaseBuilder()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡æ¡£
    doc_info = builder.document_loader.get_document_info()
    if doc_info['supported_files'] == 0:
        print("è¯·åœ¨ data/documents/ ç›®å½•ä¸­æ”¾å…¥æ–‡æ¡£æ–‡ä»¶")
        print("æ”¯æŒæ ¼å¼: PDF, TXT, DOCX, MD")
        return
        
    # æ„å»ºçŸ¥è¯†åº“
    success = builder.build_knowledge_base()
    
    if success:
        print("âœ… çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼")
        print(f"ğŸ“Š å¤„ç†äº† {doc_info['supported_files']} ä¸ªæ–‡æ¡£æ–‡ä»¶")
    else:
        print("âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥")

if __name__ == "__main__":
    main() 